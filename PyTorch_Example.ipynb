{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruWJ4cTz794Z"
      },
      "source": [
        "# Training a Neural Network with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4yVVSMZ7YGi"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D43h2egN8qm9"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "8pm7sprm8Tvb",
        "outputId": "c9862ad9-203f-4ab6-a8f8-f99e12172652"
      },
      "source": [
        "data = pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-119.562108</td>\n",
              "      <td>35.625225</td>\n",
              "      <td>28.589353</td>\n",
              "      <td>2643.664412</td>\n",
              "      <td>539.410824</td>\n",
              "      <td>1429.573941</td>\n",
              "      <td>501.221941</td>\n",
              "      <td>3.883578</td>\n",
              "      <td>207300.912353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.005166</td>\n",
              "      <td>2.137340</td>\n",
              "      <td>12.586937</td>\n",
              "      <td>2179.947071</td>\n",
              "      <td>421.499452</td>\n",
              "      <td>1147.852959</td>\n",
              "      <td>384.520841</td>\n",
              "      <td>1.908157</td>\n",
              "      <td>115983.764387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-124.350000</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.499900</td>\n",
              "      <td>14999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-121.790000</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1462.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>790.000000</td>\n",
              "      <td>282.000000</td>\n",
              "      <td>2.566375</td>\n",
              "      <td>119400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-118.490000</td>\n",
              "      <td>34.250000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2127.000000</td>\n",
              "      <td>434.000000</td>\n",
              "      <td>1167.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>3.544600</td>\n",
              "      <td>180400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-118.000000</td>\n",
              "      <td>37.720000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>3151.250000</td>\n",
              "      <td>648.250000</td>\n",
              "      <td>1721.000000</td>\n",
              "      <td>605.250000</td>\n",
              "      <td>4.767000</td>\n",
              "      <td>265000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-114.310000</td>\n",
              "      <td>41.950000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>37937.000000</td>\n",
              "      <td>6445.000000</td>\n",
              "      <td>35682.000000</td>\n",
              "      <td>6082.000000</td>\n",
              "      <td>15.000100</td>\n",
              "      <td>500001.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          longitude      latitude  ...  median_income  median_house_value\n",
              "count  17000.000000  17000.000000  ...   17000.000000        17000.000000\n",
              "mean    -119.562108     35.625225  ...       3.883578       207300.912353\n",
              "std        2.005166      2.137340  ...       1.908157       115983.764387\n",
              "min     -124.350000     32.540000  ...       0.499900        14999.000000\n",
              "25%     -121.790000     33.930000  ...       2.566375       119400.000000\n",
              "50%     -118.490000     34.250000  ...       3.544600       180400.000000\n",
              "75%     -118.000000     37.720000  ...       4.767000       265000.000000\n",
              "max     -114.310000     41.950000  ...      15.000100       500001.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EIP1OaJOFak",
        "outputId": "96f3b8e4-82b8-48e0-e04d-904db15ec4d4"
      },
      "source": [
        "#Fill NaN values\n",
        "data = data.fillna(0)\n",
        "#Normalize values\n",
        "data = (data-data.mean())/data.std()\n",
        "#Separate features and targets\n",
        "x_df = pd.DataFrame(data, columns=data.columns[:-1])\n",
        "y_df = pd.DataFrame(data, columns=[data.columns[-1]])\n",
        "#Save in tensors\n",
        "x = torch.tensor(x_df.values, dtype=torch.float)\n",
        "y = torch.tensor(y_df.values, dtype=torch.float)\n",
        "\n",
        "print(f\"x shape: {x.shape}\")\n",
        "print(f\"y shape: {y.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: torch.Size([17000, 8])\n",
            "y shape: torch.Size([17000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i10vl9KnOwfE"
      },
      "source": [
        "## Create a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTlyzUiG8p5V"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, D_in, H1, H2, H3, D_out):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.linear2 = nn.Linear(H1, H2)\n",
        "        self.linear3 = nn.Linear(H2, H3)\n",
        "        self.linear4 = nn.Linear(H3, D_out)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h1 = self.linear1(x)\n",
        "        h2 = self.linear2(h1)\n",
        "        h3 = self.linear3(h2)\n",
        "        out = self.linear4(h3)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXAcc2dLPPUe"
      },
      "source": [
        "#Define layer sizes\n",
        "D_in = x.shape[1]\n",
        "H1 = 128\n",
        "H2 = 64\n",
        "H3 = 32\n",
        "D_out = 1\n",
        "\n",
        "#Define Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#Initialize model, loss, optimizer\n",
        "model = Net(D_in, H1, H2, H3, D_out)\n",
        "loss_func = nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#Initialize dataloader\n",
        "dataset = torch.utils.data.TensorDataset(x, y)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ENFPjgHSCAV",
        "outputId": "99b8f721-1ee0-40ef-e99a-2f8c83a52722"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (linear1): Linear(in_features=8, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (linear4): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWzZl_LRTd6J"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fck--1cFP1Rd",
        "outputId": "58acb26f-822a-4a5c-a6de-90681ceae6c2"
      },
      "source": [
        "for epoch in range(100):\n",
        "  batch_losses = []\n",
        "\n",
        "  for x_batch, y_batch in dataloader:\n",
        "    y_pred = model(x_batch)\n",
        "    \n",
        "    loss = loss_func(y_pred, y_batch)\n",
        "    batch_losses.append(loss.item())\n",
        "    \n",
        "    #Delete previously stored gradients\n",
        "    optimizer.zero_grad()\n",
        "    #Perform backpropagation starting from the loss calculated in this epoch\n",
        "    loss.backward()\n",
        "    #Update model's weights based on the gradients calculated during backprop\n",
        "    optimizer.step()\n",
        "  \n",
        "  print(f\"Epoch {epoch:3}: Loss = {sum(batch_losses)/len(dataloader):.5f}\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Loss = 23.03230\n",
            "Epoch   1: Loss = 23.00585\n",
            "Epoch   2: Loss = 23.00443\n",
            "Epoch   3: Loss = 23.02430\n",
            "Epoch   4: Loss = 23.02099\n",
            "Epoch   5: Loss = 23.03321\n",
            "Epoch   6: Loss = 23.00538\n",
            "Epoch   7: Loss = 23.00858\n",
            "Epoch   8: Loss = 23.02187\n",
            "Epoch   9: Loss = 23.00640\n",
            "Epoch  10: Loss = 23.03558\n",
            "Epoch  11: Loss = 23.00467\n",
            "Epoch  12: Loss = 23.02168\n",
            "Epoch  13: Loss = 23.03198\n",
            "Epoch  14: Loss = 23.02035\n",
            "Epoch  15: Loss = 23.03098\n",
            "Epoch  16: Loss = 23.02864\n",
            "Epoch  17: Loss = 23.00796\n",
            "Epoch  18: Loss = 22.98849\n",
            "Epoch  19: Loss = 23.01406\n",
            "Epoch  20: Loss = 23.02653\n",
            "Epoch  21: Loss = 22.98048\n",
            "Epoch  22: Loss = 23.05250\n",
            "Epoch  23: Loss = 23.02554\n",
            "Epoch  24: Loss = 22.98849\n",
            "Epoch  25: Loss = 23.02380\n",
            "Epoch  26: Loss = 23.03623\n",
            "Epoch  27: Loss = 23.03491\n",
            "Epoch  28: Loss = 22.98315\n",
            "Epoch  29: Loss = 23.01919\n",
            "Epoch  30: Loss = 23.01855\n",
            "Epoch  31: Loss = 23.03876\n",
            "Epoch  32: Loss = 23.01102\n",
            "Epoch  33: Loss = 23.01832\n",
            "Epoch  34: Loss = 23.04427\n",
            "Epoch  35: Loss = 23.01305\n",
            "Epoch  36: Loss = 23.03183\n",
            "Epoch  37: Loss = 23.00532\n",
            "Epoch  38: Loss = 23.04253\n",
            "Epoch  39: Loss = 23.03134\n",
            "Epoch  40: Loss = 23.01303\n",
            "Epoch  41: Loss = 23.03506\n",
            "Epoch  42: Loss = 22.98380\n",
            "Epoch  43: Loss = 23.02340\n",
            "Epoch  44: Loss = 23.01202\n",
            "Epoch  45: Loss = 23.00425\n",
            "Epoch  46: Loss = 23.01139\n",
            "Epoch  47: Loss = 23.02624\n",
            "Epoch  48: Loss = 23.03406\n",
            "Epoch  49: Loss = 23.02773\n",
            "Epoch  50: Loss = 23.02450\n",
            "Epoch  51: Loss = 23.03175\n",
            "Epoch  52: Loss = 22.99333\n",
            "Epoch  53: Loss = 23.01222\n",
            "Epoch  54: Loss = 23.01862\n",
            "Epoch  55: Loss = 22.97159\n",
            "Epoch  56: Loss = 23.02965\n",
            "Epoch  57: Loss = 23.02394\n",
            "Epoch  58: Loss = 23.02493\n",
            "Epoch  59: Loss = 23.02404\n",
            "Epoch  60: Loss = 23.01183\n",
            "Epoch  61: Loss = 23.03981\n",
            "Epoch  62: Loss = 23.01815\n",
            "Epoch  63: Loss = 23.02528\n",
            "Epoch  64: Loss = 23.00824\n",
            "Epoch  65: Loss = 23.03466\n",
            "Epoch  66: Loss = 23.00562\n",
            "Epoch  67: Loss = 23.02409\n",
            "Epoch  68: Loss = 23.00249\n",
            "Epoch  69: Loss = 23.04673\n",
            "Epoch  70: Loss = 23.01714\n",
            "Epoch  71: Loss = 23.00854\n",
            "Epoch  72: Loss = 23.01352\n",
            "Epoch  73: Loss = 23.01531\n",
            "Epoch  74: Loss = 23.02816\n",
            "Epoch  75: Loss = 23.00707\n",
            "Epoch  76: Loss = 23.02850\n",
            "Epoch  77: Loss = 22.99725\n",
            "Epoch  78: Loss = 22.99281\n",
            "Epoch  79: Loss = 23.03149\n",
            "Epoch  80: Loss = 23.00768\n",
            "Epoch  81: Loss = 23.01014\n",
            "Epoch  82: Loss = 23.01570\n",
            "Epoch  83: Loss = 23.02131\n",
            "Epoch  84: Loss = 23.00639\n",
            "Epoch  85: Loss = 23.02216\n",
            "Epoch  86: Loss = 23.01556\n",
            "Epoch  87: Loss = 23.01870\n",
            "Epoch  88: Loss = 23.01181\n",
            "Epoch  89: Loss = 23.00933\n",
            "Epoch  90: Loss = 23.00169\n",
            "Epoch  91: Loss = 23.01277\n",
            "Epoch  92: Loss = 23.01854\n",
            "Epoch  93: Loss = 22.99196\n",
            "Epoch  94: Loss = 23.04137\n",
            "Epoch  95: Loss = 22.99936\n",
            "Epoch  96: Loss = 23.02363\n",
            "Epoch  97: Loss = 22.99446\n",
            "Epoch  98: Loss = 23.01697\n",
            "Epoch  99: Loss = 23.01041\n"
          ]
        }
      ]
    }
  ]
}